{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef317c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a646f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first query: case data\n",
    "query = \"\"\"\n",
    "\n",
    "SELECT\n",
    "        crm.employee_key, crm.employee_name, call_chat.agent_path, skill_category, first_queue, last_queue, workday_id,bot_involved_flag,\n",
    "        call_chat.case_key, call_chat.incidentlevel2reason, crm.sub_line_of_business__c, call_chat.wait_time, call_chat.complete_duration, call_chat.avg_response_cust, call_chat.avg_response_agnt, call_chat.agent_handle_time, call_chat.close_time,\n",
    "        call_chat.no_of_upfront_sla_breach, call_chat.no_of_turns_per_conversation, call_chat.no_of_agents, call_chat.agent_tenure_days, Z.resolution_days, Z.customer_tenure_days,\n",
    "        call_chat.csatscore, call_chat.cesscore, call_chat.agentsatisfactionscore, call_chat.fcrscore, call_chat.fiscal_qtr\n",
    "    FROM\n",
    "    (SELECT * FROM\n",
    "    ce_analytics.fact_agg_call_chat where sales_support_flag = 'Support') call_chat\n",
    "    join\n",
    "    (select * from ce_analytics.dim_Crm_employee) crm\n",
    "    on \n",
    "    crm.employee_key = call_chat.latest_employee_key\n",
    "    \n",
    "  \n",
    "    JOIN\n",
    "    (SELECT transaction_no, resolution_days, customer_tenure_days from ce_analytics.fact_closed_case) Z\n",
    "    ON\n",
    "    call_chat.case_key = Z.transaction_no\n",
    "    WHERE\n",
    "    call_chat.language_key = '13'\n",
    "    AND\n",
    "    call_chat.data_source = 'LE'\n",
    "    \n",
    " \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01996c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = connection.read_sql(query, conn = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ac5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_string(string):\n",
    "    lis = string.split('||')\n",
    "    new = '||'.join(lis[:-1])\n",
    "    return (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14847f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_string('40BA0A16-52E1-E911-A870-000D3A3722D6||DYNAMIC_CRM||2021-04-22')  \n",
    "all_data['new_employee_key'] = all_data.employee_key.map(check_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more agent data\n",
    "\n",
    "query = \"\"\"\n",
    "select agent_case_handling_number.*, employee_key, Date, day_working_hours, day_billable_hour\n",
    "\n",
    "from\n",
    "( select latest_employee_key, date(date_parse(interaction_starttime,'%Y-%m-%d %H:%i:%s')) as day,  \n",
    "    count(vendorid) as number_cases\n",
    "    from ce_analytics.fact_agg_call_chat \n",
    "    group by latest_employee_key, date(date_parse(interaction_starttime,'%Y-%m-%d %H:%i:%s'))\n",
    "    ) agent_case_handling_number\n",
    "\n",
    "right join\n",
    "(\n",
    "select employee_key, date(date_parse(cal_date,'%Y-%m-%d %H:%i:%s')) as Date, sum(login_time)/3600.00 as day_working_hours, \n",
    "sum(billable_hour)/3600.00 as day_billable_hour \n",
    "\n",
    "from \n",
    "(select * from ce_analytics.fact_agent_productivity_combined where cal_date not like '%2022-04%' and \n",
    "cal_date not like '%2022-03%' and cal_date not like '%2022-05%' and cal_date not like '%2022-06%') new\n",
    "\n",
    "group by employee_key, \n",
    "date(date_parse(cal_date,'%Y-%m-%d %H:%i:%s')) \n",
    ") agent_working_hours\n",
    "on agent_case_handling_number.latest_employee_key = agent_working_hours.employee_key\n",
    "and agent_case_handling_number.day = agent_working_hours.Date\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_data = connection.read_sql(query, conn = conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "agent_data['latest_employee_key'] = agent_data['latest_employee_key'].fillna(agent_data['employee_key'])\n",
    "# calculate CPH for agent level\n",
    "agent_data['day'] = agent_data['day'].fillna(agent_data['Date'])\n",
    "agent_data.number_cases = agent_data.number_cases.astype(float)\n",
    "agent_data.day_billable_hour = agent_data.day_billable_hour.astype(float)\n",
    "agent_data['CPH'] = agent_data.number_cases / agent_data.day_billable_hour \n",
    "# fill na\n",
    "agent_data.replace([np.inf], np.nan, inplace=True) \n",
    "agent_data = agent_data[agent_data.CPH <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_data.day_working_hours = agent_data.day_working_hours.astype(float)\n",
    "agent_data.day_billable_hour = agent_data.day_billable_hour.astype(float)\n",
    "agent_data.CPH = agent_data.CPH.astype(float)\n",
    "agent_data['new_employee_key'] = agent_data.latest_employee_key.map(check_string)\n",
    "\n",
    "agent = pd.DataFrame(agent_data.groupby('new_employee_key').agg({'day_working_hours':'median',\n",
    "                                                             'day_billable_hour': 'median', 'CPH': np.nanmedian,\n",
    "                                                                   'number_cases': 'sum'})).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66276ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHS data\n",
    "query = \"\"\"\n",
    "\n",
    "select * from ragupt.fact_chs_scoring\n",
    "\n",
    "\"\"\"\n",
    "chs = connection.read_sql(query = query, conn = conn)\n",
    "chs = chs.drop_duplicates()\n",
    "\n",
    "#################################################################################### merge all the infomation\n",
    "all_data_new = pd.merge(left = all_data, right = chs[['case_key', 'pred_score', 'model_prob']], on = 'case_key')\n",
    "all_data_new.head()  # 2823621\n",
    "\n",
    "case_number = pd.DataFrame(all_data_new.groupby(['employee_name','incidentlevel2reason']).case_key.count()).reset_index().rename(columns = {'case_key':'counting'})\n",
    "all_data_new = pd.merge(left = all_data_new, right = case_number, on = ['employee_name', 'incidentlevel2reason'])\n",
    "all_data_new = pd.merge(left = all_data_new, right = agent[['new_employee_key', 'day_working_hours', 'day_billable_hour', 'CPH', 'number_cases']]\n",
    "                       ,left_on = 'new_employee_key', right_on = 'new_employee_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d137cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## build a new chs score\n",
    "def new_chs(score):\n",
    "    if score <= 0.35:\n",
    "        return (0)\n",
    "    if score > 0.35 and score < 0.7:\n",
    "        return (1)\n",
    "    \n",
    "    if score >= 0.7:\n",
    "        return (2)\n",
    "\n",
    "all_data_new['sign'] = all_data_new.model_prob.map(new_chs)\n",
    "\n",
    "all_data_new['sign'].value_counts()  # remove middle value\n",
    "all_data_new_df = all_data_new[all_data_new.sign != 1]\n",
    "all_data_new_df['pred_score'].value_counts() # check the distribution of the pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################# modeling\n",
    "import pandas as pd\n",
    "from optbinning import Scorecard, BinningProcess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the train dataset\n",
    "df_all_data_new = all_data_new_df[['employee_name', 'skill_category','first_queue', 'last_queue', 'bot_involved_flag',\n",
    "                                   \n",
    "                                   'incidentlevel2reason', 'sub_line_of_business__c',\n",
    "       'wait_time', 'complete_duration', 'avg_response_cust',\n",
    "       'avg_response_agnt', 'agent_handle_time', 'close_time',\n",
    "       'no_of_upfront_sla_breach', 'no_of_turns_per_conversation',\n",
    "       'no_of_agents', 'agent_tenure_days', 'resolution_days', 'customer_tenure_days', 'csatscore', 'day_working_hours',\n",
    "       'day_billable_hour', 'CPH', 'chs', 'counting', 'number_cases']]\n",
    "df_all_data_new.csatscore = df_all_data_new.csatscore.astype(float)\n",
    "# df_all_data_new.agentsatisfactionscore = df_all_data_new.agentsatisfactionscore.astype(float)\n",
    "# df_all_data_new.fcrscore = df_all_data_new.fcrscore.astype(float)\n",
    "# df_all_data_new.cesscore = df_all_data_new.cesscore.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################### check out train and test data\n",
    "X = df_all_data_new.loc[:, df_all_data_new.columns != 'chs']\n",
    "y = df_all_data_new['chs']\n",
    "\n",
    "# Split the dataset into train and test\n",
    "df_application_train, df_application_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=5, max_iter=5000, random_state=161)\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# randomforest = RandomForestClassifier(500)\n",
    "# Define scaling method and values\n",
    "import numpy as np\n",
    "scaling_method = \"min_max\"\n",
    "scaling_method_data = {\"min\": 0, \"max\": 100}\n",
    "variable_names = np.array(X.columns)\n",
    "# Instatiate and fit Scorecard\n",
    "scorecard = Scorecard(\n",
    "    binning_process= BinningProcess(variable_names),\n",
    "    estimator=logreg,\n",
    "    scaling_method=\"min_max\",\n",
    "     scaling_method_params={\"min\": 0, \"max\": 100},\n",
    "    reverse_scorecard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard.fit(df_application_train, list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model performance\n",
    "\n",
    "from optbinning.scorecard.plots import plot_ks, plot_auc_roc\n",
    "# y_test\n",
    "# Assign score and predicted probability to test dataset\n",
    "df_application_test.loc[:,\"score\"] = scorecard.score(df_application_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa0efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC plot\n",
    "plot_auc_roc(y_test, df_application_test.score)  # done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56196170",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard.table(style=\"detailed\").to_excel('model_summary.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['score'] = scorecard.score(X)\n",
    "X['pred_score'] = y\n",
    "\n",
    "final_score = pd.DataFrame(X.groupby(['employee_name','sub_line_of_business__c', 'incidentlevel2reason']).agg({'score':'mean', 'pred_score': 'count'})).reset_index()\n",
    "\n",
    "final_score = final_score.rename(columns = {'pred_score': 'count'})\n",
    "# final output\n",
    "# final_score.pivot(index=['employee_name','sub_line_of_business__c'] ,columns='incidentlevel2reason',values=['score']).reset_index().to_excel('scorecard.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### ab testing\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "ab_test_list = ['wait_time',\n",
    "       'complete_duration', 'avg_response_cust', 'avg_response_agnt',\n",
    "       'agent_handle_time', 'close_time', 'no_of_upfront_sla_breach',\n",
    "       'no_of_turns_per_conversation', 'no_of_agents', 'agent_tenure_days',\n",
    "       'resolution_days', 'customer_tenure_days', 'csatscore', \n",
    "       'day_working_hours', 'day_billable_hour', 'CPH']\n",
    "\n",
    "for check_attribute in ab_test_list:\n",
    "    \n",
    "    if check_attribute in ['no_of_agents', 'csatscore']:\n",
    "        print (\"======\"+ check_attribute + \" crosstab and ab test===========\")\n",
    "        print (pd.crosstab(all_data_new['pred_score'], all_data_new[check_attribute]))\n",
    "        # multi proportion test\n",
    "        print ('multi proportion test')\n",
    "        print (stats.chi2_contingency(pd.crosstab(all_data_new['pred_score'], all_data_new[check_attribute])))\n",
    "        \n",
    "        \n",
    "    else: \n",
    "        print (\"======\"+ check_attribute + \" mean and ab test===========\")\n",
    "        print (all_data_new.groupby('pred_score')[check_attribute].mean())\n",
    "        print (ttest_ind(\n",
    "            all_data_new.dropna(subset = [check_attribute]).loc[all_data_new['pred_score'] == 0, check_attribute], \n",
    "            all_data_new.dropna(subset = [check_attribute]).loc[all_data_new['pred_score'] == 1, check_attribute],equal_var=True\n",
    "        ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.displot(all_data_new, x=\"model_prob\", bins=50)\n",
    "sns.displot(all_data_new[all_data_new.pred_score == 0], x=\"model_prob\", bins=50)  # < 0.2\n",
    "sns.displot(all_data_new[all_data_new.csatscore.isna()], x=\"model_prob\", bins=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
